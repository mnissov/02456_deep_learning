{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35.        ,  3.        ,  6.        , ..., -0.34839599,\n",
       "        -0.3022235 , -0.67088727],\n",
       "       [ 0.        ,  3.        ,  6.        , ..., -0.34839599,\n",
       "        -0.3022235 , -0.67088727],\n",
       "       [77.        ,  3.        ,  6.        , ..., -0.34839599,\n",
       "        -0.3022235 , -0.67088727],\n",
       "       ...,\n",
       "       [44.        ,  4.        ,  1.        , ..., -0.35568365,\n",
       "        -0.3022235 ,  0.79119077],\n",
       "       [77.        ,  4.        ,  1.        , ..., -0.35568365,\n",
       "        -0.3022235 ,  0.79119077],\n",
       "       [33.        ,  4.        ,  1.        , ..., -0.35568365,\n",
       "        -0.3022235 ,  0.79119077]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('DR_Data/rentals.pickle')\n",
    "\n",
    "X=np.array([data.pickup_zone, data.month, data.weekday, data.air_temperature, data.rain_duration, data.rain_intensity, data.GHI]).T\n",
    "y=np.array(data.dropoff_zone).T\n",
    "'''\n",
    "y = data.dropoff_zone\n",
    "X = data.drop(['created_at','finished_at','pickup_hub_id','dropoff_hub_id','user_id','dropoff_zone'], axis=1)\n",
    "'''\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "num_zones = int(max(X[:,0])+1)\n",
    "num_months = int(max(X[:,1])+1)\n",
    "num_days = int(max(X[:,2])+1)\n",
    "weather=True\n",
    "\n",
    "# RBF Encoding\n",
    "RBF_Encoding=False\n",
    "if RBF_Encoding:\n",
    "    Euc_distances_sq=np.load('DR_Data/Zone_distances.npy')\n",
    "    #Gamma = 1/2*sigma^2 and is a tuning parameter\n",
    "    gamma=0.1\n",
    "    Euc_distances=np.exp(-Euc_distances_sq*gamma)\n",
    "\n",
    "num_features = int(num_zones+num_months+num_days)\n",
    "if weather:\n",
    "    X_enc=np.zeros((int(X.shape[0]),num_features+4))\n",
    "else:\n",
    "    X_enc=np.zeros((int(X.shape[0]),num_features))\n",
    "for i in range(len(X)):\n",
    "    i=int(i)\n",
    "    if RBF_Encoding:\n",
    "        X_enc[i][:num_zones] = Euc_distances_sq[int(X[i,0])] # zone\n",
    "    else:\n",
    "        X_enc[i][int(X[i,0])] = 1 # zone\n",
    "    X_enc[i][int(X[i,1])+num_zones] = 1 # month\n",
    "    X_enc[i][int(X[i,2])+num_zones+num_months] = 1 # days\n",
    "    if weather:\n",
    "        X_enc[i,num_features:]=X[i,3:] #Encoding weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_enc, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available.\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUILDING MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = num_zones\n",
    "num_l1 = 4096\n",
    "num_l2 = 2048\n",
    "num_l3 = 512\n",
    "num_l4 = 128\n",
    "\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden1, num_hidden2, num_hidden3, num_hidden4, num_output):\n",
    "        super(Net, self).__init__()\n",
    "        # input layer\n",
    "        if weather:\n",
    "            self.W_1 = Parameter(init.kaiming_normal_(torch.Tensor(num_hidden1, num_features+4)))\n",
    "        else:\n",
    "            self.W_1 = Parameter(init.kaiming_normal_(torch.Tensor(num_hidden1, num_features)))\n",
    "        self.b_1 = Parameter(init.constant_(torch.Tensor(num_hidden1), 0))\n",
    "        # hidden layer 1\n",
    "        self.W_2 = Parameter(init.kaiming_normal_(torch.Tensor(num_hidden2, num_hidden1)))\n",
    "        self.b_2 = Parameter(init.constant_(torch.Tensor(num_hidden2), 0))\n",
    "        # hidden layer 2\n",
    "        self.W_3 = Parameter(init.kaiming_normal_(torch.Tensor(num_hidden3, num_hidden2)))\n",
    "        self.b_3 = Parameter(init.constant_(torch.Tensor(num_hidden3), 0))\n",
    "        # hidden layer 3\n",
    "        self.W_4 = Parameter(init.kaiming_normal_(torch.Tensor(num_hidden4, num_hidden3)))\n",
    "        self.b_4 = Parameter(init.constant_(torch.Tensor(num_hidden4), 0))\n",
    "         # hidden layer 4\n",
    "        self.W_5 = Parameter(init.kaiming_normal_(torch.Tensor(num_output, num_hidden4)))\n",
    "        self.b_5 = Parameter(init.constant_(torch.Tensor(num_output), 0))\n",
    "        # define activation function in constructor\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        # define dropout to reduce overfitting\n",
    "        self.drop = torch.nn.Dropout(p=0.5)\n",
    "        # define batchnorm\n",
    "        self.batch1 = torch.nn.BatchNorm1d(num_hidden1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # forward prop\n",
    "        x=x.type(torch.FloatTensor)\n",
    "        x = F.linear(x, self.W_1, self.b_1)\n",
    "        x = self.activation(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.batch1(x)\n",
    "        x = F.linear(x, self.W_2, self.b_2)\n",
    "        x = self.activation(x)\n",
    "        x = F.linear(x, self.W_3, self.b_3)\n",
    "        x = self.activation(x)\n",
    "        x = F.linear(x, self.W_4, self.b_4)\n",
    "        x = self.activation(x)\n",
    "        x = F.linear(x, self.W_5, self.b_5)\n",
    "        # dropout\n",
    "        \n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net(num_features, num_l1, num_l2,num_l3, num_l4, num_classes)\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 : Train Loss 0.008223 , Train acc 0.163772, Valid acc 0.160200\n",
      "Epoch  2 : Train Loss 0.008023 , Train acc 0.277022, Valid acc 0.277075\n",
      "Epoch  3 : Train Loss 0.007894 , Train acc 0.307478, Valid acc 0.307100\n",
      "Epoch  4 : Train Loss 0.007820 , Train acc 0.315944, Valid acc 0.315650\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# setting hyperparameters and gettings epoch sizes\n",
    "batch_size = 10000\n",
    "num_epochs = 100\n",
    "num_samples_train = X_train.shape[0]\n",
    "num_batches_train = num_samples_train // batch_size\n",
    "num_samples_valid = X_valid.shape[0]\n",
    "num_batches_valid = num_samples_valid // batch_size\n",
    "\n",
    "# setting up lists for handling loss/accuracy\n",
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "test_acc, test_loss = [], []\n",
    "cur_loss = 0\n",
    "losses = []\n",
    "\n",
    "get_slice = lambda i, size: range(i * size, (i + 1) * size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward -> Backprob -> Update params\n",
    "    ## Train\n",
    "    cur_loss = 0\n",
    "    net.train()\n",
    "    for i in range(num_batches_train):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = get_variable(Variable(torch.from_numpy(X_train[slce])))\n",
    "        output = net(x_batch)\n",
    "        \n",
    "        # compute gradients given loss\n",
    "        target_batch = get_variable(Variable(torch.from_numpy(y_train[slce]).long()))\n",
    "        batch_loss = criterion(output, target_batch)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cur_loss += batch_loss   \n",
    "    losses.append(cur_loss / batch_size)\n",
    "\n",
    "    net.eval()\n",
    "    ### Evaluate training\n",
    "    train_preds, train_targs = [], []\n",
    "    for i in range(num_batches_train):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = get_variable(Variable(torch.from_numpy(X_train[slce])))\n",
    "        \n",
    "        output = net(x_batch)\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        \n",
    "        train_targs += list(y_train[slce])\n",
    "        train_preds += list(preds.data.numpy())\n",
    "    \n",
    "    ### Evaluate validation\n",
    "    val_preds, val_targs = [], []\n",
    "    for i in range(num_batches_valid):\n",
    "        slce = get_slice(i, batch_size)\n",
    "        x_batch = get_variable(Variable(torch.from_numpy(X_valid[slce])))\n",
    "        \n",
    "        output = net(x_batch)\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        val_preds += list(preds.data.numpy())\n",
    "        val_targs += list(y_valid[slce])\n",
    "\n",
    "    train_acc_cur = accuracy_score(train_targs, train_preds)\n",
    "    valid_acc_cur = accuracy_score(val_targs, val_preds)\n",
    "    \n",
    "    train_acc.append(train_acc_cur)\n",
    "    valid_acc.append(valid_acc_cur)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(\"Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f\" % (\n",
    "                epoch+1, losses[-1], train_acc_cur, valid_acc_cur))\n",
    "\n",
    "epoch = np.arange(len(train_acc))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')\n",
    "plt.legend(['Train Accucary','Validation Accuracy'])\n",
    "plt.xlabel('Updates'), plt.ylabel('Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net,'FFNN_months_days.pt')\n",
    "#output = net(get_variable(Variable(torch.from_numpy(X_valid_enc))))\n",
    "#plt.plot(output[10].detach().numpy())\n",
    "#print(np.argmax(X_valid_enc[0]))\n",
    "#print(y_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
