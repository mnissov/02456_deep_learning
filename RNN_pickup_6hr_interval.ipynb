{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_vector_with_weekday(hubs,sin,cos,GHI,WS,AT,RA,RD,RI):\n",
    "    l = []\n",
    "    for hub in range(len(hubs)):\n",
    "        h = list(hubs[hub])\n",
    "        h.extend([sin[hub],cos[hub],GHI[hub],WS[hub],AT[hub],RA[hub],RD[hub],RI[hub]])\n",
    "        l.append(np.array(h))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1, 1578) (100, 1, 1578)\n",
      "(789, 1, 100) (789, 1, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Hubs</th>\n",
       "      <th>weekday_sin</th>\n",
       "      <th>weekday_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>GHI</th>\n",
       "      <th>wind_speed_avg</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>rain_accumulation</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-04 00:00:00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>-0.7818</td>\n",
       "      <td>0.6235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.734450</td>\n",
       "      <td>2.964500</td>\n",
       "      <td>-2.539333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-04 06:00:00</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>-0.7818</td>\n",
       "      <td>0.6235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.378000</td>\n",
       "      <td>3.860167</td>\n",
       "      <td>-2.477000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-04 12:00:00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>-0.7818</td>\n",
       "      <td>0.6235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>89.299133</td>\n",
       "      <td>4.086833</td>\n",
       "      <td>-1.904500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-03-04 18:00:00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>-0.7818</td>\n",
       "      <td>0.6235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.605567</td>\n",
       "      <td>4.434833</td>\n",
       "      <td>-1.435883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027783</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-05 00:00:00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.635395</td>\n",
       "      <td>4.933500</td>\n",
       "      <td>-0.756667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2018-03-05 06:00:00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.904333</td>\n",
       "      <td>5.455000</td>\n",
       "      <td>-1.078050</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.388733</td>\n",
       "      <td>0.002222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2018-03-05 12:00:00</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>31.912383</td>\n",
       "      <td>3.754500</td>\n",
       "      <td>-0.637500</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>2.111233</td>\n",
       "      <td>0.084440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2018-03-05 18:00:00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.981850</td>\n",
       "      <td>2.611167</td>\n",
       "      <td>0.234372</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>5.055000</td>\n",
       "      <td>0.418555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2018-03-06 00:00:00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.6235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.133000</td>\n",
       "      <td>1.115067</td>\n",
       "      <td>0.243338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2018-03-06 06:00:00</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.6235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.551667</td>\n",
       "      <td>1.671500</td>\n",
       "      <td>2.494950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index                                               Hubs  \\\n",
       "0 2018-03-04 00:00:00  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1 2018-03-04 06:00:00  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2 2018-03-04 12:00:00  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3 2018-03-04 18:00:00  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4 2018-03-05 00:00:00  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5 2018-03-05 06:00:00  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6 2018-03-05 12:00:00  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7 2018-03-05 18:00:00  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8 2018-03-06 00:00:00  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9 2018-03-06 06:00:00  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "   weekday_sin  weekday_cos  month_sin  month_cos  hour_sin  hour_cos  \\\n",
       "0      -0.7818       0.6235        1.0        0.0       0.0       1.0   \n",
       "1      -0.7818       0.6235        1.0        0.0       1.0       0.0   \n",
       "2      -0.7818       0.6235        1.0        0.0       0.0      -1.0   \n",
       "3      -0.7818       0.6235        1.0        0.0      -1.0      -0.0   \n",
       "4       0.0000       1.0000        1.0        0.0       0.0       1.0   \n",
       "5       0.0000       1.0000        1.0        0.0       1.0       0.0   \n",
       "6       0.0000       1.0000        1.0        0.0       0.0      -1.0   \n",
       "7       0.0000       1.0000        1.0        0.0      -1.0      -0.0   \n",
       "8       0.7818       0.6235        1.0        0.0       0.0       1.0   \n",
       "9       0.7818       0.6235        1.0        0.0       1.0       0.0   \n",
       "\n",
       "          GHI  wind_speed_avg  air_temperature  rain_accumulation  \\\n",
       "0   -0.734450        2.964500        -2.539333           0.000000   \n",
       "1  116.378000        3.860167        -2.477000           0.000000   \n",
       "2   89.299133        4.086833        -1.904500           0.000000   \n",
       "3   -0.605567        4.434833        -1.435883           0.000000   \n",
       "4   -0.635395        4.933500        -0.756667           0.000000   \n",
       "5   46.904333        5.455000        -1.078050           0.000083   \n",
       "6   31.912383        3.754500        -0.637500           0.001472   \n",
       "7   -0.981850        2.611167         0.234372           0.007027   \n",
       "8   -2.133000        1.115067         0.243338           0.000000   \n",
       "9  290.551667        1.671500         2.494950           0.000000   \n",
       "\n",
       "   rain_duration  rain_intensity  \n",
       "0       0.000000        0.000000  \n",
       "1       0.000000        0.000000  \n",
       "2       0.083350        0.000000  \n",
       "3       0.027783        0.000000  \n",
       "4       0.250000        0.000000  \n",
       "5       1.388733        0.002222  \n",
       "6       2.111233        0.084440  \n",
       "7       5.055000        0.418555  \n",
       "8       0.000000        0.000000  \n",
       "9       0.000000        0.000000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('DR_Data/pickup_series_6h_weather.pickle')\n",
    "pickups_out = np.array(data.Hubs)\n",
    "weekday = False\n",
    "added_features = 0\n",
    "if weekday:\n",
    "    data.Hubs = extend_vector_with_weekday(data.Hubs,data.weekday_sin,data.weekday_cos,data.GHI,data.wind_speed_avg,data.air_temperature, data.rain_accumulation, data.rain_duration, data.rain_intensity)\n",
    "    added_features = added_features + 8\n",
    "    \n",
    "pickups_in = np.array(data.Hubs)\n",
    "\n",
    "num_zones = pickups_in[0].shape[0] - added_features # -2 from weekdays sin and cos\n",
    "seq_length = 1\n",
    "num_intervals = pickups_in.shape[0]-seq_length\n",
    "num_features = pickups_in[0].shape[0] \n",
    "\n",
    "X = np.zeros((num_features, seq_length, num_intervals))\n",
    "y = np.zeros((num_zones, 1, num_intervals))\n",
    "for i in range(num_intervals):\n",
    "    X[:,:,i] = np.array(list(pickups_in[i:i+seq_length])).T\n",
    "    y[:,:,i] = np.array([pickups_out[i+seq_length]]).T\n",
    "    \n",
    "print(X.shape,y.shape)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X.transpose(), y.transpose(), test_size=0.5, random_state=1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(list(pickups_in[i:i+4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functions\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, Dropout2d, MaxPool2d, BatchNorm1d, BatchNorm2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available.\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n",
    "use_cuda =False\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (bn0): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (rnn_1): LSTM(100, 8)\n",
      "  (l_out): Linear(in_features=8, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn_seq_length = seq_length\n",
    "rnn_input_size = num_features\n",
    "rnn_hidden_size = 8\n",
    "rnn_direction = 0\n",
    "\n",
    "rnn_out_features = rnn_seq_length*rnn_hidden_size*(rnn_direction+1)\n",
    "features_cat_size = rnn_out_features\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()        \n",
    "        self.drop = Dropout(p=0.5)\n",
    "        self.bn0 = BatchNorm1d(rnn_seq_length)\n",
    "        \n",
    "        self.rnn_1 = nn.LSTM(input_size=rnn_input_size,\n",
    "                            hidden_size=rnn_hidden_size,\n",
    "                            num_layers=1,\n",
    "                            bidirectional=(rnn_direction>0))\n",
    "        \n",
    "        self.l_out = Linear(in_features=features_cat_size,\n",
    "                            out_features=num_zones,\n",
    "                            bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        out = {}\n",
    "        #x = self.bn0(x)\n",
    "        \n",
    "        features_rnn = x.view(rnn_seq_length, -1, rnn_input_size)\n",
    "        features_rnn,_ = self.rnn_1(features_rnn)\n",
    "        features_rnn = self.drop(features_rnn)\n",
    "        \n",
    "        features_rnn = features_rnn.view(-1, rnn_out_features) #self.rnn_1.hidden_size)\n",
    "        \n",
    "        # Append features to the list \"features\"\n",
    "        features.append(features_rnn)\n",
    "        \n",
    "        ## Output layer where all features are in use ##\n",
    "        features_final = torch.cat(features, dim=1)\n",
    "        \n",
    "        #features_final = self.drop(features_final)\n",
    "        out['out'] = self.l_out(x)\n",
    "        '''\n",
    "        x, (h,c) = self.rnn_1(x)\n",
    "        #x = x.view(-1,self.rnn_1.rnn_hidden_size)\n",
    "        x = self.l_out(x)\n",
    "        return x\n",
    "        '''\n",
    "        return out['out']\n",
    "\n",
    "net = Net()\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "print(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 5 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 10 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([16, 100])) that is different to the input size (torch.Size([16, 1, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 20 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 25 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 30 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 35 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 40 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 45 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 50 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 55 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 60 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 65 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 70 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 75 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 80 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 85 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 90 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n",
      "Epoch 95 \t train loss: 3.7950159457 \t valid loss: 3.7544403928 \t valid acc: 0.5965\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "# setting hyperparameters and gettings epoch sizes\n",
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "num_samples_train = X_train.shape[0]\n",
    "num_batches_train = num_samples_train // batch_size\n",
    "num_samples_valid = X_valid.shape[0]\n",
    "num_batches_valid = num_samples_valid // batch_size\n",
    "\n",
    "# Define a loss function and optimizer for this problem\n",
    "criterion = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "def accuracy(ys, ts):\n",
    "    predictions = torch.round(ys)\n",
    "    correct_prediction = torch.eq(predictions,ts)\n",
    "    return torch.mean(correct_prediction.float())\n",
    "\n",
    "# Track loss\n",
    "train_iter = []\n",
    "train_loss, train_accs = [], []\n",
    "valid_iter = []\n",
    "valid_loss, valid_accs = [], []\n",
    "\n",
    "# For each epoch\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    # Track loss\n",
    "    epoch_training_loss = 0\n",
    "    epoch_training_accs = 0\n",
    "    epoch_validation_loss = 0\n",
    "    epoch_validation_accs = 0\n",
    "    \n",
    "    net.eval()\n",
    "    for j in range(num_batches_valid):\n",
    "        inputs = get_variable(torch.Tensor(X_valid[j * batch_size: (j + 1) * batch_size]))\n",
    "        \n",
    "        targets = get_variable(torch.Tensor(np.squeeze(y_valid[j * batch_size: (j + 1) * batch_size])))\n",
    "        # Forward pass\n",
    "        outputs = inputs\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs,targets)\n",
    "        # Update loss\n",
    "        epoch_validation_loss += loss.cpu().detach().numpy()\n",
    "        epoch_validation_accs += accuracy(outputs, targets)\n",
    "    \n",
    "    net.train()\n",
    "    for j in range(num_batches_train):\n",
    "        inputs = get_variable(torch.Tensor(X_train[j * batch_size: (j + 1) * batch_size]))\n",
    "        targets = get_variable(torch.Tensor(np.squeeze(y_train[j * batch_size: (j + 1) * batch_size])))\n",
    "        outputs = inputs\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs,targets)\n",
    "        # Backward pass\n",
    "        #optimizer.zero_grad()\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        # Update loss\n",
    "        epoch_training_loss += loss.cpu().detach().numpy()\n",
    "        epoch_training_accs += accuracy(outputs,targets)\n",
    "        \n",
    "    # Save loss for plot\n",
    "    train_loss.append(epoch_training_loss/num_batches_train)\n",
    "    train_accs.append(epoch_training_accs/num_batches_train)\n",
    "    valid_loss.append(epoch_validation_loss/num_batches_valid)\n",
    "    valid_accs.append(epoch_validation_accs/num_batches_valid)\n",
    "\n",
    "    # Print loss every 5 epochs\n",
    "    if i % 5 == 0:\n",
    "        print(f'Epoch {i} \\t train loss: {train_loss[-1]:.10f} \\t valid loss: {valid_loss[-1]:.10f} \\t valid acc: {valid_accs[-1]:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "# Plot training and validation loss\n",
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epoch, train_loss, 'r', label='Training loss',)\n",
    "plt.plot(epoch, valid_loss, 'b', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch'), plt.ylabel('MSE')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch, train_accs, 'r', label='Training Accuracy')\n",
    "plt.plot(epoch, valid_accs, 'b', label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch'), plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 2., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 2., 1.,  ..., 1., 2., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0., -2., -1.,  ..., -1., -2.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., -1.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ..., -1., -1.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  1.,  0.,  ...,  0.,  1.,  0.],\n",
       "         [ 0.,  1.,  0.,  ...,  0.,  1.,  0.],\n",
       "         [ 0., -1., -1.,  ..., -1., -1.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  1., -1.,  ...,  0.,  1.,  0.],\n",
       "         [ 0.,  1.,  0.,  ..., -1.,  0.,  0.],\n",
       "         [ 0.,  1.,  0.,  ...,  0.,  1.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0., -2., -1.,  ..., -1., -2.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., -1.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ..., -1., -1.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.,  2.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  2.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., -1.,  ..., -1., -2.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  2., -1.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  2.,  0.,  ..., -1., -1.,  0.],\n",
       "         [ 0.,  2.,  0.,  ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0., -2., -1.,  ..., -1., -2.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., -1.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ..., -1., -1.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0., -2., -1.,  ..., -1., -2.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., -1.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ..., -1., -1.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
