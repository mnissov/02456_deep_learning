{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_vector_with_weekday(hubs,cos,sin):\n",
    "    l = []\n",
    "    for hub in range(len(hubs)):\n",
    "        h = list(hubs[hub])\n",
    "        h.extend([sin[hub],cos[hub]])\n",
    "        l.append(np.array(h))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 28, 1551) (10, 1, 1551)\n",
      "(1395, 28, 12) (1395, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle('DR_Data/pickup_series_10max_zones.pickle')\n",
    "pickups_out = np.array(data.Hubs)\n",
    "weekday = True\n",
    "added_features = 0\n",
    "\n",
    "if weekday:\n",
    "    data.Hubs = extend_vector_with_weekday(data.Hubs,data.weekday_sin,data.weekday_cos)\n",
    "    added_features = added_features + 2\n",
    "    \n",
    "pickups_in = np.array(data.Hubs)\n",
    "\n",
    "num_zones = pickups_in[0].shape[0] - added_features # -2 from weekdays sin and cos\n",
    "seq_length = 28\n",
    "num_intervals = pickups_in.shape[0]-seq_length\n",
    "num_features = pickups_in[0].shape[0]\n",
    "validation_size = 0.1\n",
    "\n",
    "X = np.zeros((num_features, seq_length, num_intervals))\n",
    "y = np.zeros((num_zones, 1, num_intervals))\n",
    "for i in range(num_intervals):\n",
    "    X[:,:,i] = np.array(list(pickups_in[i:i+seq_length])).T\n",
    "    y[:,:,i] = np.array([pickups_out[i+seq_length]]).T\n",
    "    \n",
    "print(X.shape,y.shape)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X.T, y.T, test_size=validation_size, random_state=1)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functions\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, Dropout2d, MaxPool2d, BatchNorm1d, BatchNorm2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available.\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n",
    "#use_cuda =False\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (bn0): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (rnn_1): LSTM(12, 16, num_layers=2, dropout=0.5)\n",
      "  (l_out): Linear(in_features=448, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn_seq_length = seq_length\n",
    "rnn_input_size = num_features\n",
    "rnn_hidden_size = 16\n",
    "rnn_direction = 0\n",
    "rnn_layers = 2\n",
    "\n",
    "rnn_out_features = rnn_seq_length*rnn_hidden_size*(rnn_direction+1)\n",
    "features_cat_size = rnn_out_features\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()        \n",
    "        #self.drop = Dropout(p=0.5)\n",
    "        self.bn0 = BatchNorm1d(rnn_seq_length)\n",
    "        \n",
    "        self.rnn_1 = nn.LSTM(input_size=rnn_input_size,\n",
    "                            hidden_size=rnn_hidden_size,\n",
    "                            num_layers=rnn_layers,\n",
    "                            bidirectional=(rnn_direction>0),\n",
    "                            dropout=0.5)\n",
    "        \n",
    "        self.l_out = Linear(in_features=features_cat_size,\n",
    "                            out_features=num_zones,\n",
    "                            bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        out = {}\n",
    "        #x = self.bn0(x)\n",
    "        \n",
    "        features_rnn = x.view(rnn_seq_length, -1, rnn_input_size)\n",
    "        features_rnn,_ = self.rnn_1(features_rnn)\n",
    "        #features_rnn = self.drop(features_rnn)\n",
    "        \n",
    "        features_rnn = features_rnn.view(-1, rnn_out_features) #self.rnn_1.hidden_size)\n",
    "        \n",
    "        # Append features to the list \"features\"\n",
    "        features.append(features_rnn)\n",
    "        \n",
    "        ## Output layer where all features are in use ##\n",
    "        features_final = torch.cat(features, dim=1)\n",
    "        \n",
    "        #features_final = self.drop(features_final)\n",
    "        out['out'] = self.l_out(features_final)\n",
    "        '''\n",
    "        x, (h,c) = self.rnn_1(x)\n",
    "        #x = x.view(-1,self.rnn_1.rnn_hidden_size)\n",
    "        x = self.l_out(x)\n",
    "        return x\n",
    "        '''\n",
    "        return out['out']\n",
    "\n",
    "net = Net()\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t train loss: 6.8989952328 \t valid loss: 12.5165324735 \t valid acc: 0.4083\n",
      "Epoch 5 \t train loss: 4.9036442674 \t valid loss: 4.5019567735 \t valid acc: 0.3474\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Define a loss function and optimizer for this problem\n",
    "criterion = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01,momentum=0.2, weight_decay=1e-3)\n",
    "\n",
    "def accuracy(ys, ts):\n",
    "    predictions = torch.round(ys)\n",
    "    correct_prediction = torch.eq(predictions,ts)\n",
    "    return torch.mean(correct_prediction.float())\n",
    "\n",
    "# Track loss\n",
    "train_iter = []\n",
    "train_loss, train_accs = [], []\n",
    "valid_iter = []\n",
    "valid_loss, valid_accs = [], []\n",
    "\n",
    "# For each epoch\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    # Track loss\n",
    "    epoch_training_loss = 0\n",
    "    epoch_training_accs = 0\n",
    "    epoch_validation_loss = 0\n",
    "    epoch_validation_accs = 0\n",
    "    \n",
    "    net.eval()\n",
    "    for j in range(X_valid.shape[0]):\n",
    "        inputs = get_variable(torch.Tensor(X_valid[j]))\n",
    "        targets = get_variable(torch.Tensor(y_valid[j]))\n",
    "        # Forward pass\n",
    "        outputs = net.forward(inputs)\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs,targets)\n",
    "        # Update loss\n",
    "        epoch_validation_loss += loss.detach().numpy()\n",
    "        epoch_validation_accs += accuracy(outputs, targets)\n",
    "    \n",
    "    net.train()\n",
    "    for j in range(X_train.shape[0]):\n",
    "        inputs = get_variable(torch.Tensor(X_train[j]))\n",
    "        targets = get_variable(torch.Tensor(y_train[j]))\n",
    "        outputs = net.forward(inputs)\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs,targets)\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update loss\n",
    "        epoch_training_loss += loss.detach().numpy()\n",
    "        epoch_training_accs += accuracy(outputs,targets)\n",
    "        \n",
    "    # Save loss for plot\n",
    "    train_loss.append(epoch_training_loss/X_train.shape[0])\n",
    "    train_accs.append(epoch_training_accs/X_train.shape[0])\n",
    "    valid_loss.append(epoch_validation_loss/X_valid.shape[0])\n",
    "    valid_accs.append(epoch_validation_accs/X_valid.shape[0])\n",
    "\n",
    "    # Print loss every 5 epochs\n",
    "    if i % 5 == 0:\n",
    "        print(f'Epoch {i} \\t train loss: {train_loss[-1]:.10f} \\t valid loss: {valid_loss[-1]:.10f} \\t valid acc: {valid_accs[-1]:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "# Plot training and validation loss\n",
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epoch, train_loss, 'r', label='Training loss',)\n",
    "plt.plot(epoch, valid_loss, 'b', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch'), plt.ylabel('MSE')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch, train_accs, 'r', label='Training Accuracy')\n",
    "plt.plot(epoch, valid_accs, 'b', label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch'), plt.ylabel('')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
